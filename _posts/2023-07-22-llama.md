
# The model structure of LLaMA 2

Recently Meta makes the LLaMA 2 model public available. Here I will run the model and see the structure of the model.

To run the model we need to first install torch and torchrun. While I encounter error "failed to load torch._c...", the following code does not produce error:
```
python -m torch.distributed.run .py     --ckpt_dir llama-2-7b-chat/     --tokenizer_path tokenizer.model     --max_seq_len 512 --max_batch_
size 4
```
Now let's print the model by adding 
```
print(generator.model)
```
to the example_chat_completion.py file

